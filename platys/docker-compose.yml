# =======================================================================
# Platform Name            mdp-demo-platform
# Platform Stack:          trivadis/platys-modern-data-platform
# Platform Stack Version:  develop
# =======================================================================
networks:
  default:
    name: mdp-demo-platform
# enforce some dependencies
# enforce some dependencies
services:
  #  ================================== Zookeeper ========================================== #
  zookeeper-1:
    image: confluentinc/cp-zookeeper:7.6.0
    container_name: zookeeper-1
    hostname: zookeeper-1
    labels:
      com.platys.name: zookeeper
      com.platys.description: Zookeeper Node 1
    ports:
      - 2181:2181
      - 1240:1234
    environment:
      ZOOKEEPER_SERVER_ID: 1
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_INIT_LIMIT: 5
      ZOOKEEPER_SYNC_LIMIT: 2
    volumes:
      - ./data-transfer:/data-transfer
    restart: unless-stopped
#  ================================== Kafka ========================================== #
  kafka-1:
    image: confluentinc/cp-kafka:7.6.0
    container_name: kafka-1
    hostname: kafka-1
    labels:
      com.platys.name: kafka
      com.platys.description: Kafka Broker 1
    depends_on:
      - zookeeper-1
    ports:
      - 9092:9092
      - 19092:19092
      - 29092:29092
      - 39092:39092
      - 9992:9992
      - 1234:1234
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_BROKER_RACK: rack1
      KAFKA_INTER_BROKER_LISTENER_NAME: BROKER
      KAFKA_ZOOKEEPER_CONNECT: zookeeper-1:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: BROKER:PLAINTEXT,LOCAL:PLAINTEXT,DOCKERHOST:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_LISTENERS: BROKER://kafka-1:19092,LOCAL://kafka-1:39092,DOCKERHOST://kafka-1:29092,EXTERNAL://kafka-1:9092
      KAFKA_ADVERTISED_LISTENERS: BROKER://kafka-1:19092,LOCAL://localhost:39092,DOCKERHOST://${DOCKER_HOST_IP:-127.0.0.1}:29092,EXTERNAL://${PUBLIC_IP:-127.0.0.1}:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_MESSAGE_TIMESTAMP_TYPE: CreateTime
      KAFKA_MIN_INSYNC_REPLICAS: 1
      KAFKA_DELETE_TOPIC_ENABLE: 'True'
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'False'
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 100
      KAFKA_JMX_PORT: 9992
      KAFKA_JMX_OPTS: -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.local.only=false -Dcom.sun.management.jmxremote.rmi.port=9992
      KAFKA_JMX_HOSTNAME: ${PUBLIC_IP:-127.0.0.1}
      KAFKA_LOG4J_ROOT_LOGLEVEL: INFO
      KAFKA_TOOLS_LOG4J_LOGLEVEL: INFO
    volumes:
      - ./data-transfer:/data-transfer
    restart: unless-stopped
    healthcheck:
      test: curl -u superUser:superUser -fail --silent --insecure https://kafka-1:9092/kafka/v3/clusters/ --output /dev/null || exit 1
      interval: 10s
      retries: 25
      start_period: 20s
  kafka-2:
    image: confluentinc/cp-kafka:7.6.0
    container_name: kafka-2
    hostname: kafka-2
    labels:
      com.platys.name: kafka
      com.platys.description: Kafka Broker 2
    depends_on:
      - zookeeper-1
    ports:
      - 9093:9093
      - 19093:19093
      - 29093:29093
      - 39093:39093
      - 9993:9993
      - 1235:1234
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_BROKER_RACK: rack1
      KAFKA_INTER_BROKER_LISTENER_NAME: BROKER
      KAFKA_ZOOKEEPER_CONNECT: zookeeper-1:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: BROKER:PLAINTEXT,LOCAL:PLAINTEXT,DOCKERHOST:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_LISTENERS: BROKER://kafka-2:19093,LOCAL://kafka-2:39093,DOCKERHOST://kafka-2:29093,EXTERNAL://kafka-2:9093
      KAFKA_ADVERTISED_LISTENERS: BROKER://kafka-2:19093,LOCAL://localhost:39093,DOCKERHOST://${DOCKER_HOST_IP:-127.0.0.1}:29093,EXTERNAL://${PUBLIC_IP:-127.0.0.1}:9093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_MESSAGE_TIMESTAMP_TYPE: CreateTime
      KAFKA_MIN_INSYNC_REPLICAS: 1
      KAFKA_DELETE_TOPIC_ENABLE: 'True'
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'False'
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 100
      KAFKA_JMX_PORT: 9993
      KAFKA_JMX_OPTS: -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.local.only=false -Dcom.sun.management.jmxremote.rmi.port=9993
      KAFKA_JMX_HOSTNAME: ${PUBLIC_IP:-127.0.0.1}
      KAFKA_LOG4J_ROOT_LOGLEVEL: INFO
      KAFKA_TOOLS_LOG4J_LOGLEVEL: INFO
    volumes:
      - ./data-transfer:/data-transfer
    restart: unless-stopped
    healthcheck:
      test: curl -u superUser:superUser -fail --silent --insecure https://kafka-2:9093/kafka/v3/clusters/ --output /dev/null || exit 1
      interval: 10s
      retries: 25
      start_period: 20s
  kafka-3:
    image: confluentinc/cp-kafka:7.6.0
    container_name: kafka-3
    hostname: kafka-3
    labels:
      com.platys.name: kafka
      com.platys.description: Kafka Broker 3
    depends_on:
      - zookeeper-1
    ports:
      - 9094:9094
      - 19094:19094
      - 29094:29094
      - 39094:39094
      - 9994:9994
      - 1236:1234
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_BROKER_RACK: rack1
      KAFKA_INTER_BROKER_LISTENER_NAME: BROKER
      KAFKA_ZOOKEEPER_CONNECT: zookeeper-1:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: BROKER:PLAINTEXT,LOCAL:PLAINTEXT,DOCKERHOST:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_LISTENERS: BROKER://kafka-3:19094,LOCAL://kafka-3:39094,DOCKERHOST://kafka-3:29094,EXTERNAL://kafka-3:9094
      KAFKA_ADVERTISED_LISTENERS: BROKER://kafka-3:19094,LOCAL://localhost:39094,DOCKERHOST://${DOCKER_HOST_IP:-127.0.0.1}:29094,EXTERNAL://${PUBLIC_IP:-127.0.0.1}:9094
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_MESSAGE_TIMESTAMP_TYPE: CreateTime
      KAFKA_MIN_INSYNC_REPLICAS: 1
      KAFKA_DELETE_TOPIC_ENABLE: 'True'
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'False'
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 100
      KAFKA_JMX_PORT: 9994
      KAFKA_JMX_OPTS: -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.local.only=false -Dcom.sun.management.jmxremote.rmi.port=9994
      KAFKA_JMX_HOSTNAME: ${PUBLIC_IP:-127.0.0.1}
      KAFKA_LOG4J_ROOT_LOGLEVEL: INFO
      KAFKA_TOOLS_LOG4J_LOGLEVEL: INFO
    volumes:
      - ./data-transfer:/data-transfer
    restart: unless-stopped
    healthcheck:
      test: curl -u superUser:superUser -fail --silent --insecure https://kafka-3:9094/kafka/v3/clusters/ --output /dev/null || exit 1
      interval: 10s
      retries: 25
      start_period: 20s
  #  ================================== ksqlDB ========================================== #
  ksqldb-server-1:
    image: confluentinc/ksqldb-server:0.29.0
    hostname: ksqldb-server-1
    container_name: ksqldb-server-1
    labels:
      com.platys.name: ksqldb
      com.platys.description: ksqlDB Streaming Database - Node 1
      com.platys.restapi.title: ksqlDB Server REST API
      com.platys.restapi.url: http://dataplatform:8088
    ports:
      - 8088:8088
      - 1095:1095
    environment:
      KSQL_LOG4J_OPTS: -Dlog4j.configuration=file:/tmp/log4j.properties
      KSQL_LOG4J_LOGGERS: org.apache.kafka.connect.runtime.rest=WARN,org.reflections=ERROR
      KSQL_LOG4J_PROCESSING_LOG_TOPIC: ksql_processing_log
      KSQL_LOG4J_PROCESSING_LOG_BROKERLIST: kafka-1:19092,kafka-2:19093,kafka-3:19094
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_NAME: ksql_processing_log
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_REPLICATION_FACTOR: 1
      KSQL_KSQL_LOGGING_PROCESSING_ROWS_INCLUDE: 'true'
      KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: 'true'
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: 'true'
      # For Demo purposes: improve resource utilization and avoid timeouts
      KSQL_KSQL_STREAMS_NUM_STREAM_THREADS: 1
      KSQL_PRODUCER_ENABLE_IDEMPOTENCE: 'true'
      KSQL_KSQL_PERSISTENCE_DEFAULT_FORMAT_KEY: KAFKA
      KSQL_APPLICATION_ID: ksqldb-cluster
      KSQL_KSQL_SERVICE_ID: ksqldb-cluster
      KSQL_HOST_NAME: ksqldb-server-1
      KSQL_LISTENERS: http://0.0.0.0:8088
      KSQL_BOOTSTRAP_SERVERS: kafka-1:19092,kafka-2:19093,kafka-3:19094
      KSQL_CACHE_MAX_BYTES_BUFFERING: 0
      KSQL_RESPONSE_HTTP_HEADERS_CONFIG: ''
      KSQL_SECURITY_PROTOCOL: PLAINTEXT
      KSQL_KSQL_SCHEMA_REGISTRY_URL: http://schema-registry-1:8081
      KSQL_KSQL_INTERNAL_TOPIC_REPLICAS: 1
      KSQL_KSQL_SINK_REPLICAS: 1
      KSQL_KSQL_STREAMS_REPLICATION_FACTOR: 1
      KSQL_KSQL_QUERY_PULL_METRICS_ENABLED: 'true'
      KSQL_KSQL_HIDDEN_TOPICS: ^_.*,default_ksql_processing_log
      KSQL_KSQL_SUPPRESS_ENABLED: 'False'
      KSQL_KSQL_SUPPRESS_BUFFER_SIZE_BYTES: '-1'
      KSQL_KSQL_QUERY_PULL_TABLE_SCAN_ENABLED: 'False'
      KSQL_CONFIG_DIR: /etc/ksqldb
      KSQL_KSQL_EXTENSION_DIR: /etc/ksqldb/ext/
      KSQL_JMX_OPTS: -Djava.rmi.server.hostname=localhost -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=1095 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.rmi.port=1095
    volumes:
      - ./data-transfer:/data-transfer
      - ./plugins/ksqldb:/etc/ksqldb/ext
      - ./conf/ksqldb/etc/log4j.properties:/tmp/log4j.properties.templ
      - ./plugins/kafka-connect/connectors:/etc/kafka-connect/addl-plugins
      - ./plugins/kafka-connect/jars:/etc/kafka-connect/jars
      - ./plugins/opentelemetry/agents:/otel
    command:
      # In the command section, $ are replaced with $$ to avoid the error 'Invalid interpolation format for "command" option'
      - bash
      - -c
      - |
        python -c 'import os,sys; sys.stdout.write(os.path.expandvars(sys.stdin.read()))' < /tmp/log4j.properties.templ > /tmp/log4j.properties
        #
        echo "Launching ksqlDB server"
        #/etc/confluent/docker/run &
        /usr/bin/docker/run &
        #
        sleep infinity
    restart: unless-stopped
    healthcheck:
      start_period: 10s
      interval: 10s
      retries: 20
      test: curl --user ksqlDBUser:ksqlDBUser -fail --silent http://ksqldb-server-1:8088/info | grep RUNNING 1>/dev/null || exit 1
  # Access the cli by running:
  # > docker exec -it ksqldb-cli ksql http://ksqldb-server-1:8088
  ksqldb-cli:
    image: confluentinc/ksqldb-cli:0.29.0
    container_name: ksqldb-cli
    hostname: ksqldb-cli
    labels:
      com.platys.name: ksqldb-cli
      com.platys.description: ksqlDB Command Line Utility
    depends_on:
      - ksqldb-server-1
    volumes:
      - ./data-transfer:/data-transfer
    entrypoint: /bin/sh
    tty: true
    restart: unless-stopped
  #  ================================== Confluent Schema Registry ========================================== #
  schema-registry-1:
    image: confluentinc/cp-schema-registry:7.6.0
    hostname: schema-registry-1
    container_name: schema-registry-1
    labels:
      com.platys.name: schema-registry
      com.platys.description: Confluent Schema Registry
      com.platys.restapi.title: Schema Registry REST API
      com.platys.restapi.url: http://dataplatform:8081
    ports:
      - 8081:8081
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry-1
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: kafka-1:19092,kafka-2:19093,kafka-3:19094
      SCHEMA_REGISTRY_GROUP_ID: schema-registry
      SCHEMA_REGISTRY_LEADER_ELIGIBILITY: 'True'
      SCHEMA_REGISTRY_MODE_MUTABILITY: 'True'
      SCHEMA_REGISTRY_SCHEMA_COMPATIBILITY_LEVEL: backward
      SCHEMA_REGISTRY_KAFKASTORE_TOPIC_REPLICATION_FACTOR: 1
      SCHEMA_REGISTRY_ACCESS_CONTROL_ALLOW_ORIGIN: '*'
      SCHEMA_REGISTRY_ACCESS_CONTROL_ALLOW_METHODS: GET,POST,PUT,OPTIONS
      SCHEMA_REGISTRY_LOG4J_ROOT_LOGLEVEL: info
      SCHEMA_REGISTRY_DEBUG: 'False'
      SCHEMA_REGISTRY_KAFKASTORE_SECURITY_PROTOCOL: PLAINTEXT
    volumes:
      - ./data-transfer:/data-transfer
      - ./plugins/opentelemetry/agents:/otel
    restart: unless-stopped
    healthcheck:
      start_period: 10s
      interval: 10s
      retries: 20
      test: curl --user superUser:superUser --fail --silent --insecure https://schema-registry-1:8081/subjects --output /dev/null || exit 1
  #  ================================== Apache Kafka HQ (AKHQ) ========================================== #
  akhq:
    image: tchiotludo/akhq:latest
    container_name: akhq
    hostname: akhq
    labels:
      com.platys.name: akhq
      com.platys.description: Kafka GUI
      com.platys.webui.title: AKHQ UI
      com.platys.webui.url: http://dataplatform:28107
      com.platys.restapi.title: AKHQ API
      com.platys.restapi.url: http://dataplatform:28107/api
    ports:
      - 28107:8080
      - 28320:28081
    environment:
      AKHQ_CONFIGURATION: |
        akhq:
          pagination.page-size: 25
          topic-data:
            size: 50
            poll-timeout: 1000
            kafka-max-message-length: 1000000
          ui-options:
            topic:
              default-view: HIDE_INTERNAL
              skip-consumer-groups: false
              skip-last-record: true
              show-all-consumer-groups: true
            topic-data:
              sort: OLDEST
          connections:
            docker-kafka-server:
              properties:
                bootstrap.servers: 'kafka-1:19092,kafka-2:19093,kafka-3:19094'
              schema-registry:
                url: "http://schema-registry-1:8081"
                type: "confluent"
              ksqldb:
                - name: "ksqldb"
                  url: "http://ksqldb-server-1:8088"
    volumes:
      - ./data-transfer:/data-transfer
    restart: unless-stopped
  #  ================================== Apache Spark 2.x ========================================== #
  spark-master:
    image: trivadis/apache-spark-master:3.2.4-hadoop3.3
    container_name: spark-master
    hostname: spark-master
    labels:
      com.platys.name: spark
      com.platys.description: Spark Master Node
      com.platys.webui.title: Spark UI
      com.platys.webui.url: http://dataplatform:28304
    ports:
      - 6066:6066
      - 7077:7077
      - 28304:8080
      - 4040-4044:4040-4044
    env_file:
      - ./conf/hadoop.env
    environment:
      SPARK_PUBLIC_DNS: ${PUBLIC_IP}
      SPARK_MASTER_OPTS: -Dspark.deploy.defaultCores=2
      INIT_DAEMON_STEP: setup_spark
      MASTER: spark://spark-master:7077
      CORE_CONF_fs_s3a_endpoint: http://minio-1:9000
      CORE_CONF_fs_s3a_path_style_access: 'true'
      HIVE_SITE_CONF_fs_s3a_endpoint: http://minio-1:9000
      HIVE_SITE_CONF_fs_s3a_access_key: minio
      HIVE_SITE_CONF_fs_s3a_secret_key: mdpDemo2024!
      HIVE_SITE_CONF_fs_s3a_path_style_access: 'true'
      HIVE_SITE_CONF_fs_s3a_impl: org.apache.hadoop.fs.s3a.S3AFileSystem
      SPARK_DEFAULTS_CONF_spark_hadoop_fs_s3a_impl: org.apache.hadoop.fs.s3a.S3AFileSystem
      SPARK_DEFAULTS_CONF_spark_hadoop_fs_s3a_endpoint: http://minio-1:9000
      SPARK_DEFAULTS_CONF_spark_hadoop_fs_s3a_path_style_access: 'true'
      SPARK_DEFAULTS_CONF_spark_sql_catalogImplementation: hive
      CORE_CONF_fs_defaultFS: s3a://admin-bucket
      SPARK_DEFAULTS_CONF_spark_sql_warehouse_dir: s3a://admin-bucket/hive/warehouse
      SPARK_DEFAULTS_CONF_spark_yarn_dist_files: /spark/conf/hive-site.xml
      SPARK_DEFAULTS_CONF_spark_driver_extraJavaOptions:
      SPARK_DEFAULTS_CONF_spark_executor_extraJavaOptions:
      SPARK_DEFAULTS_CONF_spark_cores_max: 2
      SPARK_DEFAULTS_CONF_spark_executor_memory: 2048mb
#      SPARK_DEFAULTS_CONF_spark_sql_extensions: __omit_place_holder__7ed15746ec30979f1e813cd9b82132fc824651a9
#      SPARK_DEFAULTS_CONF_spark_sql_catalog_spark__catalog: __omit_place_holder__7ed15746ec30979f1e813cd9b82132fc824651a9
      SPARK_DEFAULTS_CONF_spark_sql_catalog_spark__catalog: org.apache.spark.sql.delta.catalog.DeltaCatalog
      SPARK_DEFAULTS_CONF_spark_sql_extensions: io.delta.sql.DeltaSparkSessionExtension
      SPARK_DEFAULTS_CONF_spark_sql_legacy_allowNonEmptyLocationInCTAS: 'true'
      SPARK_DEFAULTS_CONF_spark_jars_repositories:
      SPARK_DEFAULTS_CONF_spark_jars_packages: org.postgresql:postgresql:42.3.4,org.apache.spark:spark-avro_2.12:3.2.4
      SPARK_DEFAULTS_CONF_spark_jars_excludes:
      SPARK_INSTALL_JARS_PACKAGES: ',io.delta:delta-core_2.12:2.0.2,io.delta:delta-storage:2.0.2,org.apache.iceberg:iceberg-spark-runtime-3.2_2.12:1.2.1,org.apache.hudi:hudi-spark3.2-bundle_2.12:0.13.0'
      SPARK_DEFAULTS_CONF_spark_jars: /spark/jars/delta-core_2.12-2.0.2.jar,/spark/jars/delta-storage-2.0.2.jar
      SPARK_DEFAULTS_CONF_spark_jars_ivySettings:
    volumes:
      - ./data-transfer:/data-transfer
      - ./plugins/spark/jars:/extra-jars
      - ./container-volume/spark/logs/:/var/log/spark/logs
#      - ./scripts/docker/docker-maven-download.sh:/usr/src/app/docker-maven-download.sh
      - spark-vol:/spark
    restart: unless-stopped
  spark-worker-1:
    image: trivadis/apache-spark-worker:3.2.4-hadoop3.3
    container_name: spark-worker-1
    hostname: spark-worker-1
    labels:
      com.platys.name: spark
      com.platys.description: Spark Worker Node
    depends_on:
      - spark-master
    ports:
      - 28111:28111
    env_file:
      - ./conf/hadoop.env
    environment:
      SPARK_MASTER: spark://spark-master:7077
      SPARK_WORKER_WEBUI_PORT: '28111'
      SPARK_WORKER_OPTS: -Dspark.worker.cleanup.enabled=true
      SPARK_PUBLIC_DNS: ${PUBLIC_IP}
      CORE_CONF_fs_s3a_endpoint: http://minio-1:9000
      CORE_CONF_fs_s3a_path_style_access: 'true'
      HIVE_SITE_CONF_fs_s3a_endpoint: http://minio-1:9000
      HIVE_SITE_CONF_fs_s3a_access_key: minio
      HIVE_SITE_CONF_fs_s3a_secret_key: mdpDemo2024!
      HIVE_SITE_CONF_fs_s3a_path_style_access: 'true'
      HIVE_SITE_CONF_fs_s3a_impl: org.apache.hadoop.fs.s3a.S3AFileSystem
      SPARK_DEFAULTS_CONF_spark_hadoop_fs_s3a_impl: org.apache.hadoop.fs.s3a.S3AFileSystem
      SPARK_DEFAULTS_CONF_spark_hadoop_fs_s3a_endpoint: http://minio-1:9000
      SPARK_DEFAULTS_CONF_spark_hadoop_fs_s3a_path_style_access: 'true'
      SPARK_DEFAULTS_CONF_spark_sql_catalogImplementation: hive
      CORE_CONF_fs_defaultFS: s3a://admin-bucket
      SPARK_DEFAULTS_CONF_spark_sql_warehouse_dir: s3a://admin-bucket/hive/warehouse
      SPARK_DEFAULTS_CONF_spark_yarn_dist_files: /spark/conf/hive-site.xml
      SPARK_DEFAULTS_CONF_spark_driver_extraJavaOptions:
      SPARK_DEFAULTS_CONF_spark_executor_extraJavaOptions:
      SPARK_DEFAULTS_CONF_spark_cores_max: 2
      SPARK_DEFAULTS_CONF_spark_executor_memory: 2048mb
      SPARK_DEFAULTS_CONF_spark_sql_catalog_spark__catalog: org.apache.spark.sql.delta.catalog.DeltaCatalog
      SPARK_DEFAULTS_CONF_spark_sql_extensions: io.delta.sql.DeltaSparkSessionExtension
      SPARK_DEFAULTS_CONF_spark_sql_legacy_allowNonEmptyLocationInCTAS: 'true'
      SPARK_DEFAULTS_CONF_spark_jars_repositories:
      SPARK_DEFAULTS_CONF_spark_jars_packages: org.postgresql:postgresql:42.3.4,org.apache.spark:spark-avro_2.12:3.2.4,
      SPARK_DEFAULTS_CONF_spark_jars_excludes:
      SPARK_INSTALL_JARS_PACKAGES: ',io.delta:delta-core_2.12:2.0.2,io.delta:delta-storage:2.0.2,org.apache.iceberg:iceberg-spark-runtime-3.2_2.12:1.2.1,org.apache.hudi:hudi-spark3.2-bundle_2.12:0.13.0'
      SPARK_DEFAULTS_CONF_spark_jars: /spark/jars/delta-core_2.12-2.0.2.jar,/spark/jars/delta-storage-2.0.2.jar
      SPARK_DEFAULTS_CONF_spark_jars_ivySettings:
    volumes:
      - ./data-transfer:/data-transfer
      - ./plugins/spark/jars:/extra-jars
      - ./container-volume/spark/logs/:/var/log/spark/logs
    restart: unless-stopped
  spark-worker-2:
    image: trivadis/apache-spark-worker:3.2.4-hadoop3.3
    container_name: spark-worker-2
    hostname: spark-worker-2
    labels:
      com.platys.name: spark
      com.platys.description: Spark Worker Node
    depends_on:
      - spark-master
    ports:
      - 28112:28112
    env_file:
      - ./conf/hadoop.env
    environment:
      SPARK_MASTER: spark://spark-master:7077
      SPARK_WORKER_WEBUI_PORT: '28112'
      SPARK_WORKER_OPTS: -Dspark.worker.cleanup.enabled=true
      SPARK_PUBLIC_DNS: ${PUBLIC_IP}
      CORE_CONF_fs_s3a_endpoint: http://minio-1:9000
      CORE_CONF_fs_s3a_path_style_access: 'true'
      HIVE_SITE_CONF_fs_s3a_endpoint: http://minio-1:9000
      HIVE_SITE_CONF_fs_s3a_access_key: minio
      HIVE_SITE_CONF_fs_s3a_secret_key: mdpDemo2024!
      HIVE_SITE_CONF_fs_s3a_path_style_access: 'true'
      HIVE_SITE_CONF_fs_s3a_impl: org.apache.hadoop.fs.s3a.S3AFileSystem
      SPARK_DEFAULTS_CONF_spark_hadoop_fs_s3a_impl: org.apache.hadoop.fs.s3a.S3AFileSystem
      SPARK_DEFAULTS_CONF_spark_hadoop_fs_s3a_endpoint: http://minio-1:9000
      SPARK_DEFAULTS_CONF_spark_hadoop_fs_s3a_path_style_access: 'true'
      SPARK_DEFAULTS_CONF_spark_sql_catalogImplementation: hive
      CORE_CONF_fs_defaultFS: s3a://admin-bucket
      SPARK_DEFAULTS_CONF_spark_sql_warehouse_dir: s3a://admin-bucket/hive/warehouse
      SPARK_DEFAULTS_CONF_spark_yarn_dist_files: /spark/conf/hive-site.xml
      SPARK_DEFAULTS_CONF_spark_driver_extraJavaOptions:
      SPARK_DEFAULTS_CONF_spark_executor_extraJavaOptions:
      SPARK_DEFAULTS_CONF_spark_cores_max: 2
      SPARK_DEFAULTS_CONF_spark_executor_memory: 2048mb
      SPARK_DEFAULTS_CONF_spark_sql_catalog_spark__catalog: org.apache.spark.sql.delta.catalog.DeltaCatalog
      SPARK_DEFAULTS_CONF_spark_sql_extensions: io.delta.sql.DeltaSparkSessionExtension
      SPARK_DEFAULTS_CONF_spark_sql_legacy_allowNonEmptyLocationInCTAS: 'true'
      SPARK_DEFAULTS_CONF_spark_jars_repositories:
      SPARK_DEFAULTS_CONF_spark_jars_packages: org.postgresql:postgresql:42.3.4,org.apache.spark:spark-avro_2.12:3.2.4,
      SPARK_DEFAULTS_CONF_spark_jars_excludes:
      SPARK_INSTALL_JARS_PACKAGES: ',io.delta:delta-core_2.12:2.0.2,io.delta:delta-storage:2.0.2,org.apache.iceberg:iceberg-spark-runtime-3.2_2.12:1.2.1,org.apache.hudi:hudi-spark3.2-bundle_2.12:0.13.0'
      SPARK_DEFAULTS_CONF_spark_jars: /spark/jars/delta-core_2.12-2.0.2.jar,/spark/jars/delta-storage-2.0.2.jar
      SPARK_DEFAULTS_CONF_spark_jars_ivySettings:
    volumes:
      - ./data-transfer:/data-transfer
      - ./plugins/spark/jars:/extra-jars
      - ./container-volume/spark/logs/:/var/log/spark/logs
    restart: unless-stopped
  spark-worker-3:
    image: trivadis/apache-spark-worker:3.2.4-hadoop3.3
    container_name: spark-worker-3
    hostname: spark-worker-3
    labels:
      com.platys.name: spark
      com.platys.description: Spark Worker Node
    depends_on:
      - spark-master
    ports:
      - 28113:28113
    env_file:
      - ./conf/hadoop.env
    environment:
      SPARK_MASTER: spark://spark-master:7077
      SPARK_WORKER_WEBUI_PORT: '28113'
      SPARK_WORKER_OPTS: -Dspark.worker.cleanup.enabled=true
      SPARK_PUBLIC_DNS: ${PUBLIC_IP}
      CORE_CONF_fs_s3a_endpoint: http://minio-1:9000
      CORE_CONF_fs_s3a_path_style_access: 'true'
      HIVE_SITE_CONF_fs_s3a_endpoint: http://minio-1:9000
      HIVE_SITE_CONF_fs_s3a_access_key: minio
      HIVE_SITE_CONF_fs_s3a_secret_key: mdpDemo2024!
      HIVE_SITE_CONF_fs_s3a_path_style_access: 'true'
      HIVE_SITE_CONF_fs_s3a_impl: org.apache.hadoop.fs.s3a.S3AFileSystem
      SPARK_DEFAULTS_CONF_spark_hadoop_fs_s3a_impl: org.apache.hadoop.fs.s3a.S3AFileSystem
      SPARK_DEFAULTS_CONF_spark_hadoop_fs_s3a_endpoint: http://minio-1:9000
      SPARK_DEFAULTS_CONF_spark_hadoop_fs_s3a_path_style_access: 'true'
      SPARK_DEFAULTS_CONF_spark_sql_catalogImplementation: hive
      CORE_CONF_fs_defaultFS: s3a://admin-bucket
      SPARK_DEFAULTS_CONF_spark_sql_warehouse_dir: s3a://admin-bucket/hive/warehouse
      SPARK_DEFAULTS_CONF_spark_yarn_dist_files: /spark/conf/hive-site.xml
      SPARK_DEFAULTS_CONF_spark_driver_extraJavaOptions:
      SPARK_DEFAULTS_CONF_spark_executor_extraJavaOptions:
      SPARK_DEFAULTS_CONF_spark_cores_max: 2
      SPARK_DEFAULTS_CONF_spark_executor_memory: 2048mb
      SPARK_DEFAULTS_CONF_spark_sql_catalog_spark__catalog: org.apache.spark.sql.delta.catalog.DeltaCatalog
      SPARK_DEFAULTS_CONF_spark_sql_extensions: io.delta.sql.DeltaSparkSessionExtension
      SPARK_DEFAULTS_CONF_spark_sql_legacy_allowNonEmptyLocationInCTAS: 'true'
      SPARK_DEFAULTS_CONF_spark_jars_repositories:
      SPARK_DEFAULTS_CONF_spark_jars_packages: org.postgresql:postgresql:42.3.4,org.apache.spark:spark-avro_2.12:3.2.4,
      SPARK_DEFAULTS_CONF_spark_jars_excludes:
      SPARK_INSTALL_JARS_PACKAGES: ',io.delta:delta-core_2.12:2.0.2,io.delta:delta-storage:2.0.2,org.apache.iceberg:iceberg-spark-runtime-3.2_2.12:1.2.1,org.apache.hudi:hudi-spark3.2-bundle_2.12:0.13.0'
      SPARK_DEFAULTS_CONF_spark_jars: /spark/jars/delta-core_2.12-2.0.2.jar,/spark/jars/delta-storage-2.0.2.jar
      SPARK_DEFAULTS_CONF_spark_jars_ivySettings:
    volumes:
      - ./data-transfer:/data-transfer
      - ./plugins/spark/jars:/extra-jars
      - ./container-volume/spark/logs/:/var/log/spark/logs
    restart: unless-stopped
  spark-thriftserver:
    image: trivadis/apache-spark-thriftserver:3.2.4-hadoop3.3
    container_name: spark-thriftserver
    hostname: spark-thriftserver
    labels:
      com.platys.name: spark-thriftserver
      com.platys.description: Spark Thriftserver
      com.platys.webui.title: Spark Thriftserver UI
      com.platys.webui.url: http://dataplatform:28298
    ports:
      - 28118:10000
      - 28298:4040
    env_file:
      - ./conf/hadoop.env
    environment:
      SPARK_MASTER: spark://spark-master:7077
      CORE_CONF_fs_s3a_endpoint: http://minio-1:9000
      CORE_CONF_fs_s3a_path_style_access: 'true'
      HIVE_SITE_CONF_fs_s3a_endpoint: http://minio-1:9000
      HIVE_SITE_CONF_fs_s3a_access_key: minio
      HIVE_SITE_CONF_fs_s3a_secret_key: mdpDemo2024!
      HIVE_SITE_CONF_fs_s3a_path_style_access: 'true'
      HIVE_SITE_CONF_fs_s3a_impl: org.apache.hadoop.fs.s3a.S3AFileSystem
      SPARK_DEFAULTS_CONF_spark_hadoop_fs_s3a_impl: org.apache.hadoop.fs.s3a.S3AFileSystem
      SPARK_DEFAULTS_CONF_spark_hadoop_fs_s3a_endpoint: http://minio-1:9000
      SPARK_DEFAULTS_CONF_spark_hadoop_fs_s3a_path_style_access: 'true'
      SPARK_DEFAULTS_CONF_spark_sql_catalogImplementation: hive
      CORE_CONF_fs_defaultFS: s3a://admin-bucket
      SPARK_DEFAULTS_CONF_spark_sql_warehouse_dir: s3a://admin-bucket/hive/warehouse
      SPARK_DEFAULTS_CONF_spark_sql_catalog_spark__catalog: org.apache.spark.sql.delta.catalog.DeltaCatalog
      SPARK_DEFAULTS_CONF_spark_sql_extensions: io.delta.sql.DeltaSparkSessionExtension
      SPARK_DEFAULTS_CONF_spark_sql_legacy_allowNonEmptyLocationInCTAS: 'true'
      SPARK_DEFAULTS_CONF_spark_yarn_dist_files: /spark/conf/hive-site.xml
      SPARK_DEFAULTS_CONF_spark_driver_extraJavaOptions:
      SPARK_DEFAULTS_CONF_spark_executor_extraJavaOptions:
      SPARK_DEFAULTS_CONF_spark_jars_repositories:
      SPARK_DEFAULTS_CONF_spark_jars_packages: org.postgresql:postgresql:42.3.4,org.apache.spark:spark-avro_2.12:3.2.4,
      SPARK_DEFAULTS_CONF_spark_jars_excludes:
      SPARK_INSTALL_JARS_PACKAGES: ',io.delta:delta-core_2.12:2.0.2,io.delta:delta-storage:2.0.2,org.apache.iceberg:iceberg-spark-runtime-3.2_2.12:1.2.1,org.apache.hudi:hudi-spark3.2-bundle_2.12:0.13.0'
      SPARK_DEFAULTS_CONF_spark_jars: /spark/jars/delta-core_2.12-2.0.2.jar,/spark/jars/delta-storage-2.0.2.jar
      SPARK_DEFAULTS_CONF_spark_jars_ivySettings:
    volumes:
      - ./data-transfer:/data-transfer
      - ./plugins/spark/jars:/extra-jars
      - ./container-volume/spark/logs/:/var/log/spark/logs
      - ./scripts/docker/wait-for-it.sh:/usr/src/app/wait-for-it.sh
    command: [/usr/src/app/wait-for-it.sh, hive-metastore:9083, --timeout=120, --, ./thriftserver.sh]
    restart: unless-stopped
  #  ================================== Apache Hive Metastore ========================================== #
  hive-metastore:
    image: trivadis/apache-hive:3.1.2-postgresql-metastore-s3
    container_name: hive-metastore
    hostname: hive-metastore
    labels:
      com.platys.name: hive-metastore
      com.platys.description: Hive Metastore
    ports:
      - 9083:9083
    env_file:
      - ./conf/hadoop.env
    environment:
      CORE_CONF_fs_defaultFS: s3a://admin-bucket
      CORE_CONF_fs_s3a_endpoint: http://minio-1:9000
      CORE_CONF_fs_s3a_path_style_access: 'true'
      HIVE_SITE_CONF_fs_s3a_endpoint: http://minio-1:9000
      HIVE_SITE_CONF_fs_s3a_access_key: minio
      HIVE_SITE_CONF_fs_s3a_secret_key: mdpDemo2024!
      HIVE_SITE_CONF_fs_s3a_path_style_access: 'true'
      HIVE_SITE_CONF_fs_s3a_impl: org.apache.hadoop.fs.s3a.S3AFileSystem
      # necessary for Trino to be able to read from Avro
      HIVE_SITE_CONF_metastore_storage_schema_reader_impl: org.apache.hadoop.hive.metastore.SerDeStorageSchemaReader
      SERVICE_PRECONDITION: hive-metastore-db:5432
    volumes:
      - ./data-transfer:/data-transfer
    command: /opt/hive/bin/hive --service metastore
    restart: unless-stopped
  hive-metastore-db:
    image: trivadis/apache-hive-metastore-postgresql:3.1.0-postgres9.5.3
    container_name: hive-metastore-db
    hostname: hive-metastore-db
    labels:
      com.platys.name: hive-metastore
      com.platys.description: Hive Metastore DB
    volumes:
      - ./data-transfer:/data-transfer
    restart: unless-stopped
  #  ================================== NiFi ========================================== #
  nifi-1:
    image: apache/nifi:1.25.0
    container_name: nifi-1
    hostname: nifi-1
    labels:
      com.platys.name: nifi
      com.platys.description: NiFi Data Integration Engine
      com.platys.webui.title: Apache NiFi UI
      com.platys.webui.url: https://dataplatform:18080/nifi
      com.platys.restapi.title: Apche NiFi REST API
      com.platys.restapi.url: https://dataplatform:18080/nifi-api
    ports:
      # HTTP
      - 18080:18080
      # Remote Input Socket
      - 10005:10005/tcp
      # Prometheus Port
      - 1270:1234
      - 28510:28510
    environment:
      NIFI_WEB_HTTPS_PORT: '18080'
      NIFI_WEB_HTTPS_HOST: nifi-1
      NIFI_WEB_PROXY_HOST: ${PUBLIC_IP}:18080,${DOCKER_HOST_IP}:18080
      AUTH: tls
      KEYSTORE_PATH: /opt/certs/keystore.jks
      KEYSTORE_TYPE: JKS
      KEYSTORE_PASSWORD: BWt7eLC4R53N4bIxdZEVPhAdkYlQ0Le8Tw0erGXpvI0
      KEY_PASSWORD: BWt7eLC4R53N4bIxdZEVPhAdkYlQ0Le8Tw0erGXpvI0
      TRUSTSTORE_PATH: /opt/certs/truststore.jks
      TRUSTSTORE_TYPE: JKS
      TRUSTSTORE_PASSWORD: PkhvPAirou5R/K9HQxVk99uT+hehM7SRURyFSbxTlTQ
      NIFI_SECURITY_USER_AUTHORIZER: single-user-authorizer
      NIFI_SECURITY_USER_LOGIN_IDENTITY_PROVIDER: single-user-provider
      S3_ENDPOINT: http://minio-1:9000
      S3_PATH_STYLE_ACCESS: 'true'
      S3_REGION: us-east-1
      PLATYS_AWS_ACCESS_KEY: minio
      PLATYS_AWS_SECRET_ACCESS_KEY: mdpDemo2024!
      NIFI_REMOTE_INPUT_SOCKET_PORT: '10005'
      NIFI_REMOTE_INPUT_HOST: nifi-1
      NIFI_SENSITIVE_PROPS_KEY: 12345678901234567890A
      SINGLE_USER_CREDENTIALS_USERNAME: nifi
      SINGLE_USER_CREDENTIALS_PASSWORD: mdpDemo2024!
      INITIAL_ADMIN_IDENTITY: nifi
      VAULT_TOKEN: mdpDemo2024!
    volumes:
      - ./data-transfer:/data-transfer
      - ./plugins/nifi/jars/:/extra-jars/
      - ./plugins/nifi/nars/:/opt/nifi/nifi-current/extensions
      - ./security/nifi/nifi-1/keystore.jks:/opt/certs/keystore.jks
      - ./security/nifi/nifi-1/truststore.jks:/opt/certs/truststore.jks
      - ./security/nifi/s3-credentials.properties:/tmp/s3-credentials.properties.templ
    entrypoint:
      # We override the entrypoint from the docker image and therefore have to run ../scripts/start.sh from the NiFi docker image
      - bash
      - -c
      - |
        eval "echo \"$$(cat /tmp/s3-credentials.properties.templ)\"" >> s3-credentials.properties
        ../scripts/start.sh
    restart: unless-stopped
  #  ================================== NiFi Registry ========================================== #
  nifi-registry:
    image: apache/nifi-registry:1.25.0
    container_name: nifi-registry
    hostname: nifi-registry
    labels:
      com.platys.name: nifi-registry
      com.platys.description: NiFi Data Flow Registry
      com.platys.webui.title: NiFi Registry UI
      com.platys.webui.url: http://dataplatform:19090/nifi-registry
      com.platys.restapi.title: NiFi Registry REST API
      com.platys.restapi.url: http://dataplatform:19090/nifi-registry-api/about
    ports:
      - 19090:19090
    user: root
    environment:
      NIFI_REGISTRY_WEB_HTTP_PORT: 19090
      NIFI_REGISTRY_DB_URL: ''
      NIFI_REGISTRY_DB_CLASS: org.h2.Driver
      NIFI_REGISTRY_DB_DIR: /opt/nifi-registry/nifi-registry-current/database
      NIFI_REGISTRY_DB_USER: nifireg
      NIFI_REGISTRY_DB_PASS: nifireg
      NIFI_REGISTRY_FLOW_PROVIDER: file
      NIFI_REGISTRY_FLOW_STORAGE_DIR: /opt/nifi-registry/nifi-registry-current/file-flow_storage
      NIFI_REGISTRY_BUNDLE_PROVIDER: file
      NIFI_REGISTRY_BUNDLE_STORAGE_DIR: ./extension_bundles
      LOG_LEVEL: INFO
      NIFI_REGISTRY_LOGS_DIR: /opt/nifi-registry/nifi-registry-current/logs
    volumes:
      - ./data-transfer:/data-transfer
      - ./conf/nifi-registry/logback.xml.templ:/opt/nifi-registry/nifi-registry-current/conf/logback.xml
    entrypoint:
      # We override the entrypoint from the docker image and therefore have to run ../scripts/start.sh from the NiFi Registry docker image
      - bash
      - -c
      - |
        printenv | sed 's|=.*||' | while read envvarname; do sed -i "s|\$${$$envvarname}|$${!envvarname}|" /opt/nifi-registry/nifi-registry-current/conf/logback.xml; done
        ../scripts/start.sh
    restart: unless-stopped
#  ================================== Airflow ========================================== #
  airflow:
    image: apache/airflow:2.7.3-python3.10
    container_name: airflow
    hostname: airflow
    labels:
      com.platys.name: airflow
      com.platys.description: Job Orchestration & Scheduler
      com.platys.webui.title: Airflow UI
      com.platys.webui.url: http://dataplatform:28139
      com.platys.restapi.title: Airflow REST API (dags as sample)
      com.platys.restapi.url: http://dataplatform:28139/api/v1/dags
    ports:
      - 28139:8080
    command: webserver
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:abc123!@airflow-db/airflowdb
      # For backward compatibility, with Airflow <2.3
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:abc123!@airflow-db/airflowdb
      - AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://airflow:abc123!@airflow-db/airflowdb
      - AIRFLOW__CELERY__BROKER_URL=redis://:@airflow-redis:6379/0
      - AIRFLOW__CORE__FERNET_KEY= ''
      - AIRFLOW__WEBSERVER__SECRET_KEY=mdpDemo2024!
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=True
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__API__AUTH_BACKENDS=airflow.api.auth.backend.session
      - _PIP_ADDITIONAL_REQUIREMENTS=
      - AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL=300
      - AIRFLOW__WEBSERVER__EXPOSE_CONFIG=True
      - SPARK_HOME=/opt/spark
      - AIRFLOW_VAR_S3_ENDPOINT=http://minio-1:9000
      - AIRFLOW_VAR_S3_ACCESS_KEY=minio
      - AIRFLOW_VAR_S3_SECRET_ACCESS_KEY=mdpDemo2024!
      - AIRFLOW_VAR_S3_PATH_STYLE_ACCESS='true'
    volumes:
      - ./data-transfer:/data-transfer
      - ./scripts/airflow/dags:/opt/airflow/dags:Z
      - ./plugins/airflow/:/opt/airflow/plugins:Z
      - ./scripts/docker/wait-for-it.sh:/usr/src/app/wait-for-it.sh
      - spark-vol:/opt/spark:RO
    user: ${AIRFLOW_UID:-50000}:${AIRFLOW_GID:-0}
    restart: unless-stopped
  airflow-scheduler:
    image: apache/airflow:2.7.3-python3.10
    container_name: airflow-scheduler
    hostname: airflow-scheduler
    labels:
      com.platys.name: airflow
      com.platys.description: Job Orchestration & Scheduler
    command:
      - bash
      - -c
      - |
        /usr/src/app/wait-for-it.sh -t 180 airflow-db:5432
        airflow scheduler
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:abc123!@airflow-db/airflowdb
      # For backward compatibility, with Airflow <2.3
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:abc123!@airflow-db/airflowdb
      - AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://airflow:abc123!@airflow-db/airflowdb
      - AIRFLOW__CELERY__BROKER_URL=redis://:@airflow-redis:6379/0
      - AIRFLOW__CORE__FERNET_KEY= ''
      - AIRFLOW__WEBSERVER__SECRET_KEY=mdpDemo2024!
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=True
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__API__AUTH_BACKENDS=airflow.api.auth.backend.session
      - _PIP_ADDITIONAL_REQUIREMENTS=
      - AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL=300
      - AIRFLOW__WEBSERVER__EXPOSE_CONFIG=True
      - SPARK_HOME=/opt/spark
      - AIRFLOW_VAR_S3_ENDPOINT=http://minio-1:9000
      - AIRFLOW_VAR_S3_ACCESS_KEY=minio
      - AIRFLOW_VAR_S3_SECRET_ACCESS_KEY=mdpDemo2024!
      - AIRFLOW_VAR_S3_PATH_STYLE_ACCESS='true'
    volumes:
      - ./data-transfer:/data-transfer
      - ./scripts/airflow/dags:/opt/airflow/dags:Z
      - ./plugins/airflow/:/opt/airflow/plugins:Z
      - ./scripts/docker/wait-for-it.sh:/usr/src/app/wait-for-it.sh
      - spark-vol:/opt/spark:RO
    user: ${AIRFLOW_UID:-50000}:${AIRFLOW_GID:-0}
    restart: unless-stopped
  airflow-db:
    image: postgres:13
    container_name: airflow-db
    hostname: airflow-db
    labels:
      com.platys.name: airflow
      com.platys.description: Job Orchestration & Scheduler
    environment:
      - POSTGRES_DB=airflowdb
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=abc123!
    volumes:
      - ./data-transfer:/data-transfer
    restart: unless-stopped
  airflow-init:
    image: apache/airflow:2.7.3-python3.10
    container_name: airflow-init
    hostname: airflow-init
    entrypoint: /bin/bash
    # yamllint disable rule:line-length
    command:
      - -c
      - |
        function ver() {
          printf "%04d%04d%04d%04d" $${1//./ }
        }
        airflow_version=$$(AIRFLOW__LOGGING__LOGGING_LEVEL=INFO && gosu airflow airflow version)
        airflow_version_comparable=$$(ver $${airflow_version})
        min_airflow_version=2.2.0
        min_airflow_version_comparable=$$(ver $${min_airflow_version})
        if (( airflow_version_comparable < min_airflow_version_comparable )); then
          echo
          echo -e "\033[1;31mERROR!!!: Too old Airflow version $${airflow_version}!\e[0m"
          echo "The minimum Airflow version supported: $${min_airflow_version}. Only use this or higher!"
          echo
          exit 1
        fi
        if [[ -z "${AIRFLOW_UID}" ]]; then
          echo
          echo -e "\033[1;33mWARNING!!!: AIRFLOW_UID not set!\e[0m"
          echo "If you are on Linux, you SHOULD follow the instructions below to set "
          echo "AIRFLOW_UID environment variable, otherwise files will be owned by root."
          echo "For other operating systems you can get rid of the warning with manually created .env file:"
          echo "    See: https://airflow.apache.org/docs/apache-airflow/stable/howto/docker-compose/index.html#setting-the-right-airflow-user"
          echo
        fi
        one_meg=1048576
        mem_available=$$(($$(getconf _PHYS_PAGES) * $$(getconf PAGE_SIZE) / one_meg))
        cpus_available=$$(grep -cE 'cpu[0-9]+' /proc/stat)
        disk_available=$$(df / | tail -1 | awk '{print $$4}')
        warning_resources="false"
        if (( mem_available < 4000 )) ; then
          echo
          echo -e "\033[1;33mWARNING!!!: Not enough memory available for Docker.\e[0m"
          echo "At least 4GB of memory required. You have $$(numfmt --to iec $$((mem_available * one_meg)))"
          echo
          warning_resources="true"
        fi
        if (( cpus_available < 2 )); then
          echo
          echo -e "\033[1;33mWARNING!!!: Not enough CPUS available for Docker.\e[0m"
          echo "At least 2 CPUs recommended. You have $${cpus_available}"
          echo
          warning_resources="true"
        fi
        if (( disk_available < one_meg * 10 )); then
          echo
          echo -e "\033[1;33mWARNING!!!: Not enough Disk space available for Docker.\e[0m"
          echo "At least 10 GBs recommended. You have $$(numfmt --to iec $$((disk_available * 1024 )))"
          echo
          warning_resources="true"
        fi
        if [[ $${warning_resources} == "true" ]]; then
          echo
          echo -e "\033[1;33mWARNING!!!: You have not enough resources to run Airflow (see above)!\e[0m"
          echo "Please follow the instructions to increase amount of resources available:"
          echo "   https://airflow.apache.org/docs/apache-airflow/stable/howto/docker-compose/index.html#before-you-begin"
          echo
        fi
        exec /entrypoint airflow version
    # yamllint enable rule:line-length
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:abc123!@airflow-db/airflowdb
      # For backward compatibility, with Airflow <2.3
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:abc123!@airflow-db/airflowdb
      - AIRFLOW__CELERY__RESULT_BACKEND=db+postgresql://airflow:abc123!@airflow-db/airflowdb
      - AIRFLOW__CELERY__BROKER_URL=redis://:@airflow-redis:6379/0
      - AIRFLOW__CORE__FERNET_KEY= ''
      - AIRFLOW__WEBSERVER__SECRET_KEY=mdpDemo2024!
      - AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=True
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__API__AUTH_BACKENDS=airflow.api.auth.backend.session
      - _PIP_ADDITIONAL_REQUIREMENTS=
      - AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL=300
      - AIRFLOW__WEBSERVER__EXPOSE_CONFIG=True
      - _AIRFLOW_DB_UPGRADE=True
      - _AIRFLOW_WWW_USER_CREATE=True
      - _AIRFLOW_WWW_USER_USERNAME=airflow
      - _AIRFLOW_WWW_USER_PASSWORD=mdpDemo2024!
    volumes:
      - ./data-transfer:/data-transfer
    user: 0:0
    init: true
  #  ================================== Zeppelin ========================================== #
  zeppelin:
    image: trivadis/apache-zeppelin:0.10.1-spark3.2.4-hadoop3.3
    container_name: zeppelin
    hostname: zeppelin
    labels:
      com.platys.name: zeppelin
      com.platys.description: Data Science Notebook
      com.platys.webui.title: Apache Zeppelin UI
      com.platys.webui.url: http://dataplatform:28080
    ports:
      - 28080:8080
      - 6060:6060
      - 5050:5050
      - 4050-4054:4050-4054
    env_file:
      - ./conf/hadoop.env
    environment:
      CORE_CONF_fs_s3a_endpoint: http://minio-1:9000
      CORE_CONF_fs_s3a_path_style_access: 'true'
      HIVE_SITE_CONF_fs_s3a_endpoint: http://minio-1:9000
      HIVE_SITE_CONF_fs_s3a_access_key: minio
      HIVE_SITE_CONF_fs_s3a_secret_key: mdpDemo2024!
      HIVE_SITE_CONF_fs_s3a_path_style_access: 'true'
      HIVE_SITE_CONF_fs_s3a_impl: org.apache.hadoop.fs.s3a.S3AFileSystem
      SPARK_DEFAULTS_CONF_spark_hadoop_fs_s3a_impl: org.apache.hadoop.fs.s3a.S3AFileSystem
      SPARK_DEFAULTS_CONF_spark_hadoop_fs_s3a_endpoint: http://minio-1:9000
      SPARK_DEFAULTS_CONF_spark_hadoop_fs_s3a_path_style_access: 'true'
      SPARK_HADOOP_FS_S3A_ACCESS_KEY: minio
      SPARK_HADOOP_FS_S3A_SECRET_KEY: mdpDemo2024!
      # for awscli & s3cmd
      AWS_ACCESS_KEY_ID: minio
      AWS_SECRET_ACCESS_KEY: ${PLATYS_AWS_SECRET_ACCESS_KEY:-mdpDemo2024!}
      AWS_ENDPOINT: http://minio-1:9000
      AWS_DEFAULT_REGION: us-east-1
      SPARK_DEFAULTS_CONF_spark_sql_catalog_spark__catalog: org.apache.spark.sql.delta.catalog.DeltaCatalog
      SPARK_DEFAULTS_CONF_spark_sql_extensions: io.delta.sql.DeltaSparkSessionExtension
      SPARK_DEFAULTS_CONF_spark_jars_repositories:
      SPARK_DEFAULTS_CONF_spark_jars_packages: org.postgresql:postgresql:42.3.4,org.apache.spark:spark-avro_2.12:3.2.4,
      SPARK_DEFAULTS_CONF_spark_jars_excludes:
      SPARK_INSTALL_JARS_PACKAGES: ',io.delta:delta-core_2.12:2.0.2,io.delta:delta-storage:2.0.2,org.apache.iceberg:iceberg-spark-runtime-3.2_2.12:1.2.1,org.apache.hudi:hudi-spark3.2-bundle_2.12:0.13.0'
      SPARK_DEFAULTS_CONF_spark_jars: /spark/jars/delta-core_2.12-2.0.2.jar,/spark/jars/delta-storage-2.0.2.jar
      SPARK_DEFAULTS_CONF_spark_jars_ivySettings:
      SPARK_DEFAULTS_CONF_spark_sql_catalogImplementation: hive
      SPARK_DEFAULTS_CONF_spark_sql_legacy_allowNonEmptyLocationInCTAS: 'true'
      SPARK_DEFAULTS_CONF_spark_yarn_dist_files: /spark/conf/hive-site.xml
      SPARK_DEFAULTS_CONF_spark_driver_extraJavaOptions:
      SPARK_DEFAULTS_CONF_spark_executor_extraJavaOptions:
      ZEPPELIN_SPARK_MASTER: spark://spark-master:7077
      SPARK_HOME: /opt/spark
      CORE_CONF_fs_defaultFS: s3a://admin-bucket
      SPARK_DEFAULTS_CONF_spark_sql_warehouse_dir: s3a://admin-bucket/hive/warehouse
      ZEPPELIN_ADDR: 0.0.0.0
      ZEPPELIN_PORT: '8080'
      ZEPPELIN_MEM: -Xms1024m -Xmx1024m -XX:MaxMetaspaceSize=512m
      ZEPPELIN_INTERPRETER_CONNECT_TIMEOUT: 120000
      ZEPPELIN_INTERPRETER_DEP_MVNREPO: https://repo.maven.apache.org/maven2
      ZEPPELIN_ADMIN_USERNAME: admin
      ZEPPELIN_ADMIN_PASSWORD: mdpDemo2024!
      ZEPPELIN_USER_USERNAME: zeppelin
      ZEPPELIN_USER_PASSWORD: mdpDemo2024!
      # set spark-master for Zeppelin interpreter
      ZEPPELIN_NOTEBOOK_DIR: notebook
      ZEPPELIN_NOTEBOOK_CRON_ENABLE: 'True'
      PYSPARK_PYTHON: python3
      SPARK_SUBMIT_OPTIONS: ' --conf spark.ui.port=4050 --conf spark.driver.host=zeppelin --conf spark.driver.port=5050 --conf spark.driver.bindAddress=0.0.0.0 --conf spark.blockManager.port=6060 --conf spark.driver.extraJavaOptions=-Dcom.amazonaws.services.s3.enableV4 --conf spark.executor.extraJavaOptions=-Dcom.amazonaws.services.s3.enableV4'
    volumes:
      - ./data-transfer:/data-transfer
      - ./plugins/spark/jars:/extra-jars
      - ./container-volume/spark/logs/:/var/log/spark/logs
      - ./conf/awscli/s3cfg.template:/root/.s3cfg.template
      - spark-vol:/opt/spark:RO
    restart: unless-stopped
  #  ================================== Jupyter ========================================== #
  jupyter:
    image: jupyter/all-spark-notebook:spark-3.2.1
    container_name: jupyter
    hostname: jupyter
    labels:
      com.platys.name: jupyter
      com.platys.description: Web-based interactive development environment for notebooks, code, and data
      com.platys.webui.title: Jupyter UI
      com.platys.webui.url: http://dataplatform:28888
    ports:
      - 28888:8888
      - 14040-14044:4040-4044
    user: root
    extra_hosts:
      - host.docker.internal:host-gateway
    environment:
      JUPYTER_ENABLE_LAB: "'yes'"
      GRANT_SUDO: "'yes'"
      JUPYTER_TOKEN: mdpDemo2024!
      DOCKER_STACKS_JUPYTER_CMD: lab
      CORE_CONF_fs_s3a_endpoint: http://minio-1:9000
      CORE_CONF_fs_s3a_path_style_access: 'true'
      HIVE_SITE_CONF_fs_s3a_endpoint: http://minio-1:9000
      HIVE_SITE_CONF_fs_s3a_access_key: minio
      HIVE_SITE_CONF_fs_s3a_secret_key: mdpDemo2024!
      HIVE_SITE_CONF_fs_s3a_path_style_access: 'true'
      HIVE_SITE_CONF_fs_s3a_impl: org.apache.hadoop.fs.s3a.S3AFileSystem
      SPARK_DEFAULTS_CONF_spark_hadoop_fs_s3a_impl: org.apache.hadoop.fs.s3a.S3AFileSystem
      SPARK_DEFAULTS_CONF_spark_hadoop_fs_s3a_endpoint: http://minio-1:9000
      SPARK_DEFAULTS_CONF_spark_hadoop_fs_s3a_path_style_access: 'true'
      SPARK_HADOOP_FS_S3A_ACCESS_KEY: minio
      SPARK_HADOOP_FS_S3A_SECRET_KEY: mdpDemo2024!
      # for awscli & s3cmd
      AWS_ACCESS_KEY_ID: minio
      AWS_SECRET_ACCESS_KEY: ${PLATYS_AWS_SECRET_ACCESS_KEY:-mdpDemo2024!}
      AWS_ENDPOINT: http://minio-1:9000
      AWS_DEFAULT_REGION: us-east-1
    volumes:
      - ./data-transfer:/data-transfer
      - ./scripts/docker/docker-maven-download.sh:/maven-download.sh
#    #      - ./plugins/jupyter/aws-java-sdk-bundle-1.11.375.jar:/usr/local/spark/jars/aws-java-sdk-bundle-1.11.375.jar
#      - ./plugins/jupyter/hadoop-aws-3.2.1.jar:/usr/local/spark/jars/hadoop-aws-3.2.1.jar
#      - ./plugins/jupyter/guava-27.1-jre.jar:/usr/local/spark/jars/guava-14.0.1.jar
#        # - ./custom-conf/jupyter/spark-defaults.conf:/usr/local/spark-3.1.1-bin-hadoop3.2/conf/spark-defaults.conf
    #  - "./conf/jupyter/spark-defaults.conf:/usr/local/spark-3.1.1-bin-hadoop3.2/conf/spark-defaults.conf"
    command:
      # In the command section, $ are replaced with $$ to avoid the error 'Invalid interpolation format for "command" option'
      - bash
      - -c
      - |
        /maven-download.sh central com.amazonaws:aws-java-sdk-bundle:1.11.375,org.apache.hadoop:hadoop-aws:3.2.1,com.google.guava:guava:14.0.1 /usr/local/spark/jars
        start-notebook.sh
    restart: unless-stopped
  #  ================================== Redis ========================================== #
  redis-1:
    image: bitnami/redis:7.2
    hostname: redis-1
    container_name: redis-1
    labels:
      com.platys.name: redis
      com.platys.description: Key-value store
    ports:
      - 6379:6379
    environment:
      - REDIS_PORT_NUMBER=6379
      - ALLOW_EMPTY_PASSWORD=yes
      - REDIS_AOF_ENABLED=yes
      - REDIS_RDB_POLICY_DISABLED=yes
    volumes:
      - ./data-transfer:/data-transfer
    command: /opt/bitnami/scripts/redis/run.sh --loglevel notice
    restart: unless-stopped
    healthcheck:
      test: [CMD-SHELL, redis-cli --no-auth-warning ping | grep PONG]
      interval: 5s
      timeout: 3s
      retries: 5
  #  ================================== Redis Commander ========================================== #
  redis-commander:
    image: rediscommander/redis-commander:latest
    container_name: redis-commander
    hostname: redis-commander
    labels:
      com.platys.name: redis-commander
      com.platys.description: Graphical interface for Redis
      com.platys.webui.title: Redis Commander UI
      com.platys.webui.url: http://dataplatform:28119
    ports:
      - 28119:8081
    environment:
      - REDIS_HOST=redis-1
      - REDIS_PORT=6379
      - REDIS_DB=0
    volumes:
      - ./data-transfer:/data-transfer
    restart: unless-stopped
  #  ================================== PostgreSQL ========================================== #
  postgresql:
    image: postgres:16
    container_name: postgresql
    hostname: postgresql
    labels:
      com.platys.name: postgresql
      com.platys.description: Open-Source object-relational database system
    ports:
      - 5432:5432
    environment:
      - POSTGRES_PASSWORD=mdpDemo2024!
      - POSTGRES_USER=postgres
      - POSTGRES_DB=postgres
      - POSTGRES_MULTIPLE_DATABASES=demodb,starburst
      - POSTGRES_MULTIPLE_USERS=demo,starburst
      - POSTGRES_MULTIPLE_PASSWORDS=mdpDemo2024!,abc123!
      - POSTGRES_MULTIPLE_ADDL_ROLES=
      - PGDATA=/var/lib/postgresql/data/pgdata
      - DB_SCHEMA=demo
    volumes:
      - ./data-transfer:/data-transfer
      - ./init/postgresql:/docker-entrypoint-initdb.d/
    restart: unless-stopped
  #  ================================== Cloudbeaver ========================================== #
  cloudbeaver:
    image: dbeaver/cloudbeaver:latest
    container_name: cloudbeaver
    hostname: cloudbeaver
    labels:
      com.platys.name: cloudbeaver
      com.platys.description: Cloud Database Manager
      com.platys.webui.title: Cloudbeaver UI
      com.platys.webui.url: http://dataplatform:8978
    ports:
      - 8978:8978
    volumes:
      - ./data-transfer:/data-transfer
      - ./conf/cloudbeaver/data-sources.json:/opt/cloudbeaver/workspace/GlobalConfiguration/.dbeaver/data-sources.json
    restart: unless-stopped
  #  ================================== Trino ========================================== #
  trino-1:
    image: starburstdata/starburst-enterprise:435-e.4
    hostname: trino-1
    container_name: trino-1
    labels:
      com.platys.name: trino
      com.platys.description: SQL Virtualization Engine
      com.platys.webui.title: Trino UI
      com.platys.webui.url: http://dataplatform:28082
    ports:
      - 28082:8080
      - 28083:8443
    environment:
      # this is only generated to keep the structure valid if no other env variables are present
      DUMMY: make-it-valid
      DATA_PRODUCT_ENABLED: 'false'
      S3_ENDPOINT: http://minio-1:9000
      S3_AWS_ACCESS_KEY: minio
      S3_AWS_SECRET_KEY: mdpDemo2024!
      S3_PATH_STYLE_ACCESS: 'true'
      HIVE_STORAGE_FORMAT: ORC
      HIVE_COMPRESSION_CODEC: GZIP
      HIVE_VIEWS_ENABLED: 'false'
      HIVE_RUN_AS_INVOKER: 'false'
      HIVE_LEGACY_TRANSLATION: 'false'
      POSTGRESQL_DATABASE: demodb
      POSTGRESQL_USER: demo
      POSTGRESQL_PASSWORD: mdpDmeo2024!
      REDIS_TABLE_NAMES: ''
      REDIS_NODES: redis-1:6379
      EVENT_LISTENER_CONFIG_FILES: ''
    volumes:
      - ./data-transfer:/data-transfer
      - ./conf/starburstdata/single/config.properties:/etc/starburst/config.properties
      - ./conf/starburstdata/single/node.properties:/etc/starburst/node.properties
      - ./conf/starburstdata/catalog/minio.properties:/etc/starburst/catalog/minio.properties
      - ./conf/starburstdata/catalog/delta.properties:/etc/starburst/catalog/delta.properties
      - ./conf/starburstdata/catalog/postgresql.properties:/etc/starburst/catalog/postgresql.properties
      - ./conf/starburstdata/catalog/redis.properties:/etc/starburst/catalog/redis.properties
      - ./licenses/starburstdata/starburstdata.license:/etc/starburst/starburstdata.license
      - ./custom-conf/starburstdata/security:/etc/starburst/security
    restart: unless-stopped
  trino-cli:
    image: trivadis/trino-cli:latest
    hostname: trino-cli
    container_name: trino-cli
    labels:
      com.platys.name: trino
      com.platys.description: Trino CLI
    volumes:
      - ./data-transfer:/data-transfer
    tty: true
    restart: unless-stopped
  #  ================================== Minio ========================================== #
  minio-1:
    image: minio/minio:RELEASE.2024-04-06T05-26-02Z
    container_name: minio-1
    hostname: minio-1
    labels:
      com.platys.name: minio
      com.platys.description: Software-defined Object Storage
      com.platys.webui.title: MinIO UI
      com.platys.webui.url: http://dataplatform:9000
    ports:
      - 9000:9000
      - 9010:9010
    environment:
      MINIO_ROOT_USER: minio
      MINIO_ROOT_PASSWORD: mdpDemo2024!
      MINIO_REGION_NAME: us-east-1
      MINIO_DOMAIN: minio
      MINIO_SERVER_URL: http://${PUBLIC_IP}:9000
      MINIO_PROMETHEUS_AUTH_TYPE: public
      MINIO_PROMETHEUS_URL: http://prometheus-1:9090
    volumes:
      - ./data-transfer:/data-transfer
    command: server /data --console-address ":9010"
    restart: unless-stopped
    healthcheck:
      test:
        - CMD-SHELL
        - bash -c 'printf \"GET / HTTP/1.1\n\n\" > /dev/tcp/127.0.0.1/9000; exit $$?;'
      interval: 1s
      timeout: 5s
      retries: 5
  #  ================================== Minio MC ========================================== #
  minio-mc:
    image: minio/mc:latest
    container_name: minio-mc
    hostname: minio-mc
    labels:
      com.platys.name: minio
      com.platys.description: MinIO Console
    volumes:
      - ./data-transfer:/data-transfer
      - ./scripts/docker/wait-for-it.sh:/usr/src/app/wait-for-it.sh
    entrypoint:
      - /bin/sh
      - -c
      - |
        /usr/src/app/wait-for-it.sh -t 180 minio-1:9000
        mc alias set minio-1 http://minio-1:9000 minio mdpDemo2024!
        mc mb --ignore-existing minio-1/admin-bucket
           for bucket in $$(tr ',' '\n' <<< "")
        do
          mc mb --ignore-existing minio-1/$$bucket
        done
        #
        while [ 1 -eq 1 ];do sleep 60;done
    restart: unless-stopped
  #  ================================== Code-Server IDE (VS Code in Browser) ================= #
  code-server:
    image: trivadis/code-server:latest
    container_name: code-server
    hostname: code-server
    labels:
      com.platys.name: code-server
      com.platys.description: Code Editor (VS Code in Browser)
      com.platys.webui.title: Code-Server UI
      com.platys.webui.url: http://dataplatform:28140
    user: 0:0
    ports:
      - 28140:8080
    environment:
      PASSWORD: abc123!
    volumes:
      - ./data-transfer:/home/coder/data-transfer
    restart: unless-stopped
  #  ================================== File Browser ================= #
  filebrowser:
    image: hurlenko/filebrowser:latest
    container_name: filebrowser
    hostname: filebrowser
    labels:
      com.platys.name: filebrowser
      com.platys.description: File-Browser
      com.platys.webui.title: File Browser UI
      com.platys.webui.url: http://dataplatform:28178/filebrowser
    ports:
      - 28178:8080
    environment:
      - FB_BASEURL=/filebrowser
      - FB_USER=admin
      - FB_PASSWORD=$2a$10$2icoJn27Ym.AQYtjrCt.1uPrr5NE7AOqD2BewCBrCYOrntulB29Wi
    volumes:
      - ./data-transfer:/data
    user: 1000:1000
    restart: unless-stopped
  #  ================================== Vault ================= #
  vault:
    image: hashicorp/vault:1.15
    container_name: vault
    hostname: vault
    labels:
      com.platys.name: vault
      com.platys.description: Secrets management, encryption as a service, and privileged access management
      com.platys.webui.title: Vault UI
      com.platys.webui.url: http://dataplatform:8200
    ports:
      - 8200:8200
    environment:
      - VAULT_ADDR=http://0.0.0.0:8200
#      - VAULT_LOCAL_CONFIG='{"listener": [{"tcp":{"address": "0.0.0.0:8200","tls_disable":"0", "tls_cert_file":"/data/vault-volume/certificate.pem", "tls_key_file":"/data/vault-volume/key.pem"}}], "default_lease_ttl": "168h", "max_lease_ttl": "720h"}, "ui": true}'
      - VAULT_API_ADDR=http://0.0.0.0:8200
      - VAULT_ADDRESS=http://0.0.0.0:8200
      - VAULT_DEV_LISTEN_ADDRESS=0.0.0.0:8200
      - VAULT_DEV_ROOT_TOKEN_ID=mdpDemo2024!
    volumes:
      - ./data-transfer:/data-transfer
      - ./conf/vault/config:/vault/config
      - ./container-volume/vault/data:/vault/data
    cap_add:
      - IPC_LOCK
    command: vault server -dev
  #  ================================== Docker Registry ========================================== #
  docker-registry:
    image: registry:2
    container_name: docker-registry
    hostname: docker-registry
    labels:
      com.platys.name: docker-registry
      com.platys.description: Docker Registry
      com.platys.restapi.title: Docker Registry REST API
      com.platys.restapi.url: http://dataplatform:5020/v2
    ports:
      - 5020:5000
    environment:
      REGISTRY_STORAGE_FILESYSTEM_ROOTDIRECTORY: /var/lib/registry
      REGISTRY_HTTP_ADDR: 0.0.0.0:5000
      REGISTRY_HTTP_HEADERS_Access-Control-Allow-Origin: '["http://${PUBLIC_IP}:28307"]'
      REGISTRY_HTTP_HEADERS_Access-Control-Allow-Methods: '[HEAD,GET,OPTIONS,DELETE]'
      REGISTRY_HTTP_HEADERS_Access-Control-Allow-Credentials: '[true]'
      REGISTRY_HTTP_HEADERS_Access-Control-Allow-Headers: '[Authorization,Accept,Cache-Control]'
      REGISTRY_HTTP_HEADERS_Access-Control-Expose-Headers: '[Docker-Content-Digest]'
      REGISTRY_STORAGE_DELETE_ENABLED: 'true'
    volumes:
      - ./data-transfer:/data-transfer
    restart: unless-stopped
  docker-registry-ui:
    image: joxit/docker-registry-ui:latest
    container_name: docker-registry-ui
    hostname: docker-registry-ui
    labels:
      com.platys.name: docker-registry-ui
      com.platys.description: Docker Registry
      com.platys.webui.title: Docker Registry UI
      com.platys.webui.url: http://dataplatform:28307
    ports:
      - 28307:80
    depends_on:
      - docker-registry
    environment:
      SINGLE_REGISTRY: true
      REGISTRY_TITLE: Private Docker Registry
      REGISTRY_URL: http://${PUBLIC_IP}:5020
      DELETE_IMAGES: true
      SHOW_CONTENT_DIGEST: true
      REGISTRY_SECURED: false
      CATALOG_ELEMENTS_LIMIT: 1000
    volumes:
      - ./data-transfer:/data-transfer
    restart: unless-stopped
  #  ================================== Markdown Madness Server ========================================== #
  markdown-madness:
    image: dannyben/madness:latest
    container_name: markdown-madness
    hostname: markdown-madness
    labels:
      com.platys.name: markdown-madness
      com.platys.description: Markdown Server
      com.platys.webui.title: Markdown Madness Server UI
      com.platys.webui.url: http://dataplatform:28312
    ports:
      - 28312:3000
    volumes:
      - ./data-transfer:/data-transfer
      - ./data-transfer/docs:/docs
      - ./custom-conf/markdown-madness/markdown-madness.yml:/docs/.madness.yml
    command: server
    restart: unless-stopped
  #  ================================== markdown-viewer ========================================== #
  markdown-viewer:
    image: dannyben/madness:latest
    container_name: markdown-viewer
    hostname: markdown-viewer
    labels:
      com.platys.name: markdown-viewer
      com.platys.description: Platys Platform homepage viewer
      com.platys.webui.title: Markdown Viewer UI
      com.platys.webui.url: http://dataplatform:80
    ports:
      - 80:3000
    volumes:
      - ./artefacts:/docs
      - ./conf/markdown-viewer/markdown-madness.yml:/docs/.madness.yml
      - ./data-transfer:/data-transfer
    command: server
    restart: unless-stopped
    healthcheck:
      test: [CMD, curl, -f, http://dataplatform:80]
      interval: 1m30s
      timeout: 10s
      retries: 3
      start_period: 1m
  markdown-renderer:
    image: trivadis/jinja2-renderer:latest
    container_name: markdown-renderer
    hostname: markdown-renderer
    labels:
      com.platys.name: markdown-renderer
      com.platys.description: Platys Platform homepage rendering
    environment:
      USE_PUBLIC_IP: 'True'
      PUBLIC_IP: ${PUBLIC_IP}
      DOCKER_HOST_IP: ${DOCKER_HOST_IP}
      DATAPLATFORM_HOME: ${DATAPLATFORM_HOME}
      PLATYS_PLATFORM_NAME: mdp-demo-platform
      PLATYS_PLATFORM_STACK: trivadis/platys-modern-data-platform
      PLATYS_PLATFORM_STACK_VERSION: develop
      PLATYS_COPY_COOKBOOK_DATA: 'True'
      SERVICE_LIST_VERSION: 2
      PLATYS_ADDL_DOCUMENTATION: http://${PUBLIC_IP}:28312
    volumes:
      - ./artefacts/templates:/templates
      - ./artefacts/templates:/scripts
      - .:/variables
      - ./artefacts:/output
      - ./data-transfer:/data-transfer
    init: true
volumes:
  data-transfer-vol:
    name: data_transfer_vol
  spark-vol:
